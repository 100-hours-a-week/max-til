# TIL

## Date: 2025-12-01

## Today I Work : AI Model Serving with FastAPI
FastAPI를 사용하여 AI모델을 서빙한다.
- 사용 모델 : ultralytics이 제공하는 YOLO11n
- 사용 목적 : 영상 속 객체 탐지
- 이용 방법 : 영상 속에서 마우스(컴퓨터 부품)가 감지되면 스트리밍 화면에 경고문 출력

### File 1 : detector.py
1. `ObjectDetector` 객체 : 호출되면 `yolo11n.pt` 모델을 다운로드하거나 로컬에서 불러온다.
2. `process_frame` 함수 : 모델을 불러들었으면 연결된 카메라로부터 동영상 프레임을 입력받는다. 이후 yolo모델을 통해 객체 탐지를 진행하는데, `mouse`가 탐지되었으면 `mouse_detected`변수를 활성화, 좌상단에 탐지 경보를 출력한다.

### File 2 : server.py
1. FastAPI 서버
2. `detector.py` 파일에서 정의한 `ObjectDetector` 객체를 실행한다.
3. `process_frame` 함수를 통해 실제로 프레임을 가공한다.
4. 인코딩을 통해 가공된 프레임을 `jpg`형태로 압축한다. 이후 `tobytes()`함수를 통해 바이트 스트림으로 변환하고, 제네레이터 `yield`를 이용하여 `MJPEG`규격으로 바이트 스트림을 전송한다.
5. `@app.get("/video_feed")`에서 스트리밍 실행
6. `async def video_feed(cam_index: int = 0):` : Streamlit에서 `?cam_index=1` 처럼 파라미터를 보낼 수 있게 설정한다. 이후 카메라 연결테스트를 진행하는데, 카메라 연결이 안되면 503에러를 표시하도록 한다. (무한 로딩으로 인해 에러문이 계속 표시된다) 카메라가 정상적으로 연결되었으면 `StreamingResponse`을 통해 `generate_frames`함수에 카메라 번호를 입력하고 스트리밍을 실행한다.

### File 3 : app.py
1. streamlit 프론트엔드
2. 사용할 카메라를 선택하고 `카메라 연결 시작`버튼을 누른다.
3. 이후 해당 카메라의 url로 이동하고 스트리밍을 실행한다.

### Result
![](https://velog.velcdn.com/images/swoo64/post/3d735444-3496-4661-b9e0-b255aa40b28b/image.png)


## References and Links
- ![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=GitHub&logoColor=white)
- [2025-12-01.md](https://github.com/Max-JI64/Today-I-Learn/blob/main/2025-TIL/Dec/2025-12-01.md) 
- ![Google Docs](https://img.shields.io/badge/googledocs-4285F4?style=for-the-badge&logo=googledocs&logoColor=white)
- [보고서](https://docs.google.com/document/d/1J6JPfKkPX61C69KnaHHnpLfK4ah5VsmvdkKT7parcvE/edit?usp=sharing)
