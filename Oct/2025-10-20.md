# TIL Template

## Date: 2025-10-20

### Today What I Learn
#### Learn 1 : Deep Learning
대량의 데이터를 기반으로 비선형 모델을 자동으로 만들어주는 기법이다.
머신러닝은 알고리즘을 선택 후 훈련하여 하이퍼파라미터를 조정하지만, 딥러닝은 신경망 구조를 직접 설계하며 가중치와 바이어스를 최적화한다.
#### Learn 2 : Perceptron
ANN의 기본 단위로 입력값을 가중치와 함께 처리하여 단일 출력을 생성하는 선형 이진 분류기이다.  
이것은 weighted sum(가중합)과 activation function으로 구성되어 있다.  
가중합은 입력값과 가중치의 선형 결합을 의미한다. (입력값 * 가중치 + 편향)
활성화 함수의 종류에 따라 출력값은 특정 범위로 변환되며, 이진 분류 문제에서는 주로 0과 1과 같은 이진값으로 해석된다.

#### Learn 3 : Activation Function (비선형 활성화 함수)
인공신경망에서 뉴런의 출력을 결정하는 비선형 함수이다. 노드가 입력신호를 받아 가중합을 계산한 후 비선형 함수에 적용하여 최종 출력을 생성한다.  
이것은 신경망의 학습 능력과 예측 성능에 큰 영향을 미치며, 네트워크의 복잡한 패턴 인식을 가능하게 한다.
여기엔 시그모이드, 하이퍼볼릭 탄젠트, 렐루 함수 등이 있다.

#### Learn 4 : Artificial Neural Network (ANN)
인공적으로 생물학적 뉴런 신경 회로망을 모방한 것을 말한다.  
이것은 가중치를 학습하는데 크게 Feed-Forward, Loss Function, Backpropagation, Gradient Descent를 사용한다.
#### Learn 5 : Fully Connected Layer
인공신경망에서 모든 입력 뉴런이 모든 출력 뉴련과 연결된 레이어이다.  
이것은 입력 데이터의 모든 정보를 종합적으로 분석하고 학습한다.  
그러나 학습해야 할 파라미터의 수가 기하급수적으로 증가한다.  
또한 특정 데이터 패턴을 지나치게 학습하거나 불필요한 학습의 가능성이 증가하여 과적합의 문제가 발생할 수 있다.
#### Learn 6 : Loss Function
Loss Function은 인공신경망이나 머신러닝 모델에서 예측값과 실제값 간의 차이를 정량적으로 측정하는 함수이다. 모델은 예측 오차를 최소화 하는 방향으로 학습한다.  
- Regression : MSE, MAE
- Classification : Cross-Entropy Loss, Hinge Loss(주로 SVM에서 사용)

#### Learn 7 : Gradient Descent
Gradient Descent는 머신러닝과 딥러닝에서 Loss Function를 최소화하기 위해 가중치를 반복적으로 조정하는 Optimization Algorithm이다. 이것은 Loss Function의 기울기를 계산하여 가중치를 기울기의 반대 방향으로 업데이트함으로써 손실 값을 점진적으로 줄여나간다.

#### Learn 8 : Optimizer
딥러닝 모델의 손실 함수를 최소화하기 위해 기울기를 기반으로 가중치를 업데이트 하는 알고리즘
![Optimizer image](https://www.notion.so/image/attachment%3A18adff41-98ae-4b7d-bed8-6897e2d428a4%3A%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-02-12_11.04.12.png?table=block&id=1a1394a4-8061-815b-88f8-fc7ea7979d6e&spaceId=cf024025-486d-4514-84ae-3a7c5951c17c&width=1710&userId=ece291d9-c5dd-4045-8f70-92975297b0cb&cache=v2)
- Gradient Descent  
배치 경사 하강법 : 전체 데이터셋을 사용하여 한번에 가중치를 업데이트, 경로가 곧고 흔들림이 없다  
확률적 경사 하강법 : 하나의 데이터 샘플을 사용하여 가중치를 업데이트, 경로가 요동치며 불안정  
미니 배치 경사 하강법 : 데이터셋을 작은 배치로 나누어 각 배치마다 가중치를 업데이트, 어느정도 흔들리지만 전체적으로 빠르고 안정적으로 수렴  
![Gradient image](https://velog.velcdn.com/images/swoo64/post/88657d28-d66c-43d5-94c3-242ad3d2e7af/image.png)


### Today I Work
#### Work 1:


### Today's Assignment and How to Solve
#### Assignment 1 :

### Today's Memoirs
- 오늘의 학습 경험에 대한 자유로운 생각이나 느낀 점을 기록합니다.
- 성공적인 점, 개선해야 할 점, 새롭게 시도하고 싶은 방법 등을 포함할 수 있습니다.

### References and Links
- [![velog](https://img.shields.io/badge/Velog-20C997?style=for-the-badge&logo=Velog&logoColor=white)](URL)
- [![git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=Git&logoColor=white)](URL)
- [![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=GitHub&logoColor=white)](URL)
- [링크 제목](URL)
- [링크 제목](URL)
